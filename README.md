# ğŸ§  MRI T1-T2 Style Transfer using CycleGAN

![MRI T1â†”T2 Conversion Example](conversion.png)

**Author:** Ursina Sanderink  
**Technology Stack:** TensorFlow, Python  
**Model Architecture:** CycleGAN with 114+ Million Parameters

---

## ğŸ—‚ Overview

This project implements a Cycle-Consistent Generative Adversarial Network (CycleGAN) for **bidirectional transformation** between **T1-weighted** and **T2-weighted** brain MRI scans â€” *without requiring paired training data*.

The goal: Create a tool that can **generate one MRI contrast from the other** to assist clinicians, reduce patient scan time, and improve access to diagnostic imaging.

---

## ğŸ§  Problem Statement

MRI scans with different contrasts (T1, T2, etc.) provide complementary information. However, acquiring multiple sequences:

- â³ Increases scanning time  
- ğŸ’° Raises costs  
- ğŸ˜© Causes patient discomfort  
- ğŸ§­ Is not always feasible in emergencies or low-resource settings

We aim to **synthesize missing contrasts** using unpaired image-to-image translation â€” specifically T1 â†” T2 â€” using deep generative modeling.

---

## ğŸ§¬ Model Architecture

This solution is based on the **CycleGAN framework**, which consists of two generators and two discriminators trained jointly in an adversarial and cycle-consistent way.

![CycleGAN Architecture](cyclegan.png)

### ğŸ” Core Components

- **Generator G**: T1 â†’ T2 (54.4M parameters)  
- **Generator F**: T2 â†’ T1 (54.4M parameters)  
- **Discriminator X**: Distinguishes real vs fake T1  
- **Discriminator Y**: Distinguishes real vs fake T2  
- **Total Parameters**: 114,344,708

### ğŸ§  Generator Architecture â€” U-Net

To preserve spatial anatomy, the generators use a **U-Net-style encoder-decoder** with skip connections. This is essential in medical imaging.

![U-Net Architecture](unet.png)

- **8-level deep** encoder/decoder  
- **Instance normalization** for contrast adaptation  
- **Skip connections** preserve structural fidelity

### ğŸ§ª Discriminator â€” PatchGAN

Discriminators use a **70Ã—70 PatchGAN**, focusing on **local realism** rather than global structure, which speeds up training and generalizes better.

---

## âš™ï¸ GAN Principles Refresher

![GAN Architecture](ganarchitecture.png)

- **Generator**: Learns to produce realistic T1/T2 images  
- **Discriminator**: Learns to detect fake images  
- **Adversarial Loss**: Pushes realism  
- **Cycle Consistency Loss**: Enforces anatomical integrity  
- **Identity Loss**: Stabilizes color and contrast

> The model balances these losses to ensure both **realistic output** and **anatomical faithfulness**.

---

## ğŸ¥ Clinical Motivation

- â± **Reduced Scan Times**: Generate missing MRI sequences virtually  
- ğŸ˜Œ **Patient Comfort**: Shorter procedures reduce discomfort and movement  
- ğŸ’¸ **Cost Efficiency**: Streamlined radiology workflows  
- ğŸš‘ **Emergency Imaging**: Faster decisions with limited sequences  
- ğŸŒ **Global Health**: Extend diagnostic capabilities in low-resource settings

---

## ğŸ§° Technical Architecture Summary

### ğŸ”§ Key Features

- ğŸ§  **U-Net Generators**: Encoder-decoder with skip connections  
- ğŸ“¦ **PatchGAN Discriminators**  
- ğŸ§¼ **Instance Normalization**  
- ğŸ” **Cycle Consistency (Î»=10.0)**  
- ğŸ†” **Identity Loss (Î»=0.5)**  

---

## ğŸ’¡ Implementation Highlights

### ğŸ§ª Medical Image Optimizations

- Support for **16-bit grayscale DICOM-style data**  
- Specialized preprocessing to retain voxel-level detail  
- Smart augmentations to simulate real-world variability

---

## âš™ï¸ Performance

### ğŸ’» Training Specs

- **Hardware**: T4 GPU â€“ 16GB VRAM  
- **Memory Usage**: ~12GB  
- **Batch Size**: 1  
- **Speed**: ~45 sec/epoch  

### â± Training Duration

| Epochs     | Time         | Use Case         |
|------------|--------------|------------------|
| 20         | 15â€“30 min    | Quick demo       |
| 100        | 2â€“4 hours    | Good quality     |
| 200        | 6â€“8 hours    | Production level |

### ğŸ§  Model Performance

- âš¡ Inference: <1 second/image  
- ğŸ“ Input/Output: 256Ã—256Ã—1 grayscale  
- ğŸ” Cycle Recons.: High structural fidelity  
- ğŸ¨ Contrast Transfer: Realistic and accurate

---

## ğŸ”§ Key Hyperparameters

- ğŸ“‰ Learning Rate: `2e-4`  
- ğŸ§  Optimizer: Adam (Î²â‚ = 0.5)  
- ğŸ” Cycle Loss Weight: 10.0  
- ğŸ†” Identity Loss Weight: 0.5  
- ğŸ–¼ Image Resolution: 256Ã—256

---

## ğŸ’¡ Technical Innovation

- ğŸ§¬ Instance norm customized for medical domains  
- âš–ï¸ Loss balancing for structure preservation  
- ğŸ“ˆ Interactive monitoring & reproducibility  
- ğŸ’¾ Lightweight enough for free GPU use

---

## ğŸ§ª Research Contributions

- ğŸ”„ Unpaired medical image translation  
- ğŸ“ Teaching framework for GAN learners  
- ğŸ“š Reproducible and open-source medical AI research  
- ğŸ§  Bridging radiology needs with deep learning tools

---

## ğŸ“Š Results

### ğŸ“ Quantitative Metrics

- ğŸ’¾ Model Size: ~450MB (float32)  
- âš™ï¸ Parameters: 114M  
- ğŸ“ˆ Stable training with consistent convergence

### ğŸ‘ Qualitative Assessment

| Category                | Rating            |
|------------------------|-------------------|
| Anatomical Preservation| â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸         |
| Contrast Accuracy      | â­ï¸â­ï¸â­ï¸â­ï¸           |
| Artifacts              | Minimal           |
| Cycle Consistency      | High Fidelity     |

---

## ğŸ¥ Clinical Validation

**Status**: ğŸš§ Research & educational use only

**Future Steps**:

- ğŸ©» Radiologist evaluation  
- ğŸ“Š Diagnostic performance studies  
- ğŸ¥ Workflow integration  
- ğŸ›¡ Regulatory clearance

---

## ğŸ“¦ Dependencies

```python
tensorflow>=2.8.0  
numpy>=1.21.0  
matplotlib>=3.5.0  
opencv-python>=4.5.0  
pillow>=8.3.0  
tqdm>=4.62.0

## ğŸ”– Citation
If you use this implementation in your research:


@misc{sanderink2025mri_cyclegan,
  title={MRI T1-T2 Style Transfer using CycleGAN},
  author={Ursina Sanderink},
  year={2025},
  howpublished={\url{https://github.com/your-repo/mri-cyclegan}}
}

## ğŸ“„ License
MIT License â€” see LICENSE file for details.

## ğŸ™ Acknowledgments

ğŸ§  Based on CycleGAN by Zhu et al. (2017)

ğŸ’¡ Inspired by work in medical GAN research

ğŸ§ª Designed to teach & explore AI in radiology

ğŸ“ Educational bridge between imaging & deep learning

âš ï¸ Disclaimer: For research and education only. Not for clinical diagnosis or medical decision-making without regulatory approval.
